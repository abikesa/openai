```
         1. Truth
                 \
3. Knowledge ->  2. Bias-Variance ->  5. Process -> 6. Hierarchical
                 /
                  4. Ethics
```


1. ChatGPT [Tribes](https://stratechery.com/2023/openais-misalignment-and-microsofts-gain/)
2. DALLE
3. Knowledge
   - Data
     - Updated
   - Credo
     - Fixed, Varying, $\frac{\partial Y}{\partial t}$
   - [Skills](https://jhufena.github.io/home/act1/act_1_0/act_1_0_3.html)
     - To deal with the challenge of error
       

   ---

Here’s the reality of the matter, though: whether or not you agree with the Sutskever/Shear [tribe](https://stratechery.com/2023/openais-misalignment-and-microsofts-gain/), the board’s charter and responsibility is not to make money. This is not a for-profit corporation with a fiduciary duty to its shareholders; indeed, as I laid out above, OpenAI’s charter specifically states that it is “unconstrained by a need to generate financial return”. From that perspective the board is in fact doing its job, as counterintuitive as that may seem: to the extent the board believes that Altman and his tribe were not “build[ing] general-purpose artificial intelligence that benefits humanity” it is empowered to fire him; they do, and so they did.

$\vdots$

The end result is that an entity committed by charter to the safe development of AI has basically handed off all of its work and, probably soon enough, a sizable portion of its talent, to one of the largest for-profit entities on earth. Or, in an AI-relevant framing, the structure of OpenAI was ultimately misaligned with fulfilling its stated mission. Trying to organize incentives by fiat simply doesn’t account for all of the possible scenarios and variable at play in a `dynamic situation`; harvesting self-interest has, for good reason, long been the best way to align individuals and companies.
